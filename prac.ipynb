{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "torch.manual_seed(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, n_e):\n",
    "        super().__init__()\n",
    "        self.e = 1e-20\n",
    "        self.g = nn.Parameter(torch.ones(n_e))\n",
    "        self.b = nn.Parameter(torch.zeros(n_e))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        mu = X.mean(dim=-1, keepdims=True)\n",
    "        v = X.var(dim=-1, keepdims=True)\n",
    "        X = (X - mu) / (torch.sqrt(v) + self.e)\n",
    "        return self.g * X + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_e, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_e, 4 * n_e),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * n_e, n_e),\n",
    "            nn.Dropout(d),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, n_e, sz):\n",
    "        super().__init__()\n",
    "        self.sz = sz\n",
    "        self.q = nn.Linear(n_e, sz)\n",
    "        self.k = nn.Linear(n_e, sz)\n",
    "        self.v = nn.Linear(n_e, sz)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Q = self.q(X)\n",
    "        K = self.k(X)\n",
    "        V = self.v(X)\n",
    "\n",
    "        scaled_dot = Q @ torch.transpose(K, -1, -2) / self.sz ** 0.5\n",
    "        AZ = scaled_dot.masked_fill(torch.tril(scaled_dot) == 0, float('-inf'))\n",
    "        return F.softmax(AZ, dim=-1) @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHA(nn.Module):\n",
    "\n",
    "    def __init__(self, n_e, n_h):\n",
    "        super().__init__()\n",
    "        sz = n_e // n_h\n",
    "        self.h = nn.ModuleList([Head(n_e, sz) for _ in range(n_h)])\n",
    "        self.W_o = nn.Linear(sz * n_h, n_e)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        o = torch.cat([h(X) for h in self.h], dim=-1)\n",
    "        return self.W_o(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, n_e, n_h, d):\n",
    "        super().__init__()\n",
    "        self.norm_z = LayerNorm(n_e)\n",
    "        self.mha = MHA(n_e, n_h)\n",
    "        self.norm_a = LayerNorm(n_e)\n",
    "        self.mlp = FeedForward(n_e, d)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.mha(self.norm_z(x))\n",
    "        x = self.mlp(self.norm_a(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "\n",
    "    def __init__(self, conf):\n",
    "        super().__init__()\n",
    "        self.n_e, self.n_h, self.n_l, self.n_c, self.n_v, self.n_h, self.d = conf.n_e, conf.n_h, conf.n_l, conf.n_c, conf.n_v, conf.n_h, conf.d\n",
    "        self.E = nn.Embedding(self.n_v, self.n_e)\n",
    "        self.P = nn.Embedding(self.n_c, self.n_e)\n",
    "        self.layers = nn.Sequential(*[Block(self.n_e, self.n_h, self.d) for _ in range(self.n_l)])\n",
    "        self.normalize_o = LayerNorm(self.n_e)\n",
    "        self.mlp = nn.Linear(self.n_e, self.n_v)\n",
    "        self.apply(self.w_and_b)\n",
    "\n",
    "    def w_and_b(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def number_of_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        T = len(x)\n",
    "        e = self.E(x) + self.P(torch.arange(T))\n",
    "\n",
    "        a = self.layers(e)\n",
    "        Z =  self.mlp(self.normalize_o(a))\n",
    "        B, T, C = Z.shape\n",
    "\n",
    "        if y is not None:\n",
    "            y = y.view(B*T)\n",
    "            Z = Z.view(B*T, C)\n",
    "            loss = F.cross_entropy(Z, y)\n",
    "        else:\n",
    "            loss = None\n",
    "        return Z, loss\n",
    "\n",
    "    def create(self, p, max_new_tokens):\n",
    "        \"\"\" p -- a prompt-like \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            p = p[:, - self.n_c:]\n",
    "            Z, loss = self(p)\n",
    "            Z = Z[:, -1, :]\n",
    "            probs = F.softmax(Z, dim=-1)\n",
    "            new_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            p = torch.cat((p, new_token), dim=1)\n",
    "\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GPT_conf:\n",
    "    n_c: int = 8\n",
    "    n_e: int = 8\n",
    "    n_h: int = 4\n",
    "    n_l: int = 6\n",
    "    n_v: int = 27\n",
    "    d: float = 0.2\n",
    "    batch_size: int = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = GPT_conf()\n",
    "model = GPTModel(conf)\n",
    "print(f'Number of parameters = {model.number_of_parameters():,}')\n",
    "\n",
    "lr = 3e-4\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "L = []\n",
    "\n",
    "batch_loader = utils.load_batch()\n",
    "\n",
    "for b in range(10_000):\n",
    "    break\n",
    "    Z, loss = model(X, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    l = loss.item()\n",
    "    if b % 1000 == 0:\n",
    "        print(l)\n",
    "    L.append(l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGdCAYAAAAbudkLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlOUlEQVR4nO3df1BU973/8RfyYwMOnAiG3ewNJmSGa1RsazGDqBOdUdFWwmTaW5Nitt7EUTv+ykZN1Nv2xmRuQEmjaaUxktupuUms+ae0pkmp3NZLw1XEwdKqMdpOiWJ0xbbrggkBAuf7h5PzvQvWaLt44MPzMbN/cPbN7uecccIzH3aXONu2bQEAABhohNsLAAAAGCiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjJbi9ADf19vbq3LlzSk1NVVxcnNvLAQAA18G2bbW3t8vv92vEiGvv2Qzr0Dl37pyysrLcXgYAAPg7tLS06I477rjmzA2Hzm9+8xs999xzamxs1Pnz51VVVaUHHnjAud+2bT399NOqrKxUOBxWfn6+fvCDH2jChAnOTGdnp9atW6cf//jH6ujo0KxZs/Tiiy9GLTYcDmv16tXau3evJKm4uFjbt2/Xrbfe6sycOXNGK1as0K9//WslJyerpKRE3/3ud5WUlHRd55KamirpyoVKS0u70UsBAABc0NbWpqysLOfn+LXccOh8+OGH+vznP69HHnlEX/3qV/vdX15erq1bt2rXrl3653/+Z/3Hf/yH5syZo5MnTzoLCgaDevPNN7Vnzx5lZGRo7dq1KioqUmNjo+Lj4yVJJSUlOnv2rKqrqyVJS5cuVSAQ0JtvvilJ6unp0fz583Xbbbeprq5Of/nLX7Ro0SLZtq3t27df17l8+uuqtLQ0QgcAgCHmul52Yv8DJNlVVVXO1729vbbP57M3b97sHPv4449ty7Lsl156ybZt27506ZKdmJho79mzx5n54IMP7BEjRtjV1dW2bdv2u+++a0uy6+vrnZmDBw/akuz33nvPtm3bfvvtt+0RI0bYH3zwgTPz4x//2PZ4PHYkErmu9UciEVvSdc8DAAD33cjP75i+66q5uVmhUEiFhYXOMY/HoxkzZujAgQOSpMbGRnV3d0fN+P1+5ebmOjMHDx6UZVnKz893ZqZMmSLLsqJmcnNz5ff7nZm5c+eqs7NTjY2NV11fZ2en2traom4AAMBcMQ2dUCgkSfJ6vVHHvV6vc18oFFJSUpJGjRp1zZnMzMx+j5+ZmRk10/d5Ro0apaSkJGemr7KyMlmW5dx4ITIAAGYbkM/R6fs7M9u2P/P3aH1nrjb/98z8Xxs3blQkEnFuLS0t11wTAAAY2mIaOj6fT5L67ai0trY6uy8+n09dXV0Kh8PXnLlw4UK/x7948WLUTN/nCYfD6u7u7rfT8ymPx+O88JgXIAMAYL6Yhk52drZ8Pp9qamqcY11dXaqtrdXUqVMlSXl5eUpMTIyaOX/+vI4dO+bMFBQUKBKJqKGhwZk5dOiQIpFI1MyxY8d0/vx5Z2bfvn3yeDzKy8uL5WkBAIAh6obfXn758mX98Y9/dL5ubm5WU1OT0tPTNWbMGAWDQZWWlionJ0c5OTkqLS1VSkqKSkpKJEmWZWnx4sVau3atMjIylJ6ernXr1mnixImaPXu2JGncuHGaN2+elixZop07d0q68vbyoqIijR07VpJUWFio8ePHKxAI6LnnntNf//pXrVu3TkuWLGGnBgAAXHGjb+nav3+/LanfbdGiRbZtX3mL+VNPPWX7fD7b4/HY9913n3306NGox+jo6LBXrlxpp6en28nJyXZRUZF95syZqJm//OUv9sKFC+3U1FQ7NTXVXrhwoR0Oh6NmTp8+bc+fP99OTk6209PT7ZUrV9off/zxdZ8Lby8HAGDouZGf33G2bdsudpar2traZFmWIpEIu0AAAAwRN/Lzm79eDgAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMdcOfowPg+ty14S23l6D3N893ewkA4Cp2dAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGinnofPLJJ/r2t7+t7OxsJScn6+6779Yzzzyj3t5eZ8a2bW3atEl+v1/JycmaOXOmjh8/HvU4nZ2dWrVqlUaPHq2RI0equLhYZ8+ejZoJh8MKBAKyLEuWZSkQCOjSpUuxPiUAADBExTx0tmzZopdeekkVFRU6ceKEysvL9dxzz2n79u3OTHl5ubZu3aqKigodPnxYPp9Pc+bMUXt7uzMTDAZVVVWlPXv2qK6uTpcvX1ZRUZF6enqcmZKSEjU1Nam6ulrV1dVqampSIBCI9SkBAIAhKs62bTuWD1hUVCSv16sf/vCHzrGvfvWrSklJ0auvvirbtuX3+xUMBrV+/XpJV3ZvvF6vtmzZomXLlikSiei2227Tq6++qgcffFCSdO7cOWVlZentt9/W3LlzdeLECY0fP1719fXKz8+XJNXX16ugoEDvvfeexo4d+5lrbWtrk2VZikQiSktLi+VlAHTXhrfcXoLe3zzf7SUAQMzdyM/vmO/oTJ8+Xb/61a906tQpSdLvfvc71dXV6ctf/rIkqbm5WaFQSIWFhc73eDwezZgxQwcOHJAkNTY2qru7O2rG7/crNzfXmTl48KAsy3IiR5KmTJkiy7Kcmb46OzvV1tYWdQMAAOZKiPUDrl+/XpFIRPfcc4/i4+PV09OjZ599Vl//+tclSaFQSJLk9Xqjvs/r9er06dPOTFJSkkaNGtVv5tPvD4VCyszM7Pf8mZmZzkxfZWVlevrpp/+xEwQAAENGzHd03njjDb322mvavXu3jhw5oldeeUXf/e539corr0TNxcXFRX1t23a/Y331nbna/LUeZ+PGjYpEIs6tpaXlek8LAAAMQTHf0XniiSe0YcMGPfTQQ5KkiRMn6vTp0yorK9OiRYvk8/kkXdmRuf32253va21tdXZ5fD6furq6FA6Ho3Z1WltbNXXqVGfmwoUL/Z7/4sWL/XaLPuXxeOTxeGJzogAAYNCL+Y7ORx99pBEjoh82Pj7eeXt5dna2fD6fampqnPu7urpUW1vrRExeXp4SExOjZs6fP69jx445MwUFBYpEImpoaHBmDh06pEgk4swAAIDhLeY7Ovfff7+effZZjRkzRhMmTNBvf/tbbd26VY8++qikK79uCgaDKi0tVU5OjnJyclRaWqqUlBSVlJRIkizL0uLFi7V27VplZGQoPT1d69at08SJEzV79mxJ0rhx4zRv3jwtWbJEO3fulCQtXbpURUVF1/WOKwAAYL6Yh8727dv1ne98R8uXL1dra6v8fr+WLVumf//3f3dmnnzySXV0dGj58uUKh8PKz8/Xvn37lJqa6sxs27ZNCQkJWrBggTo6OjRr1izt2rVL8fHxzszrr7+u1atXO+/OKi4uVkVFRaxPCQAADFEx/xydoYTP0cFA4nN0AGBguPo5OgAAAIMFoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYCW4vABgod214y+0lAABcxo4OAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAY/G3rgCDuf33vt7fPN/V5wcAdnQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxBiR0PvjgAz388MPKyMhQSkqKvvCFL6ixsdG537Ztbdq0SX6/X8nJyZo5c6aOHz8e9RidnZ1atWqVRo8erZEjR6q4uFhnz56NmgmHwwoEArIsS5ZlKRAI6NKlSwNxSgAAYAiKeeiEw2FNmzZNiYmJ+sUvfqF3331Xzz//vG699VZnpry8XFu3blVFRYUOHz4sn8+nOXPmqL293ZkJBoOqqqrSnj17VFdXp8uXL6uoqEg9PT3OTElJiZqamlRdXa3q6mo1NTUpEAjE+pQAAMAQFWfbth3LB9ywYYP+93//V++8885V77dtW36/X8FgUOvXr5d0ZffG6/Vqy5YtWrZsmSKRiG677Ta9+uqrevDBByVJ586dU1ZWlt5++23NnTtXJ06c0Pjx41VfX6/8/HxJUn19vQoKCvTee+9p7Nixn7nWtrY2WZalSCSitLS0GF0BDBZ3bXjL7SUMe+9vnu/2EgAY6EZ+fsd8R2fv3r2aPHmyvva1rykzM1OTJk3Syy+/7Nzf3NysUCikwsJC55jH49GMGTN04MABSVJjY6O6u7ujZvx+v3Jzc52ZgwcPyrIsJ3IkacqUKbIsy5npq7OzU21tbVE3AABgrpiHzp/+9Cft2LFDOTk5+uUvf6lvfvObWr16tf7rv/5LkhQKhSRJXq836vu8Xq9zXygUUlJSkkaNGnXNmczMzH7Pn5mZ6cz0VVZW5ryex7IsZWVl/WMnCwAABrWYh05vb6+++MUvqrS0VJMmTdKyZcu0ZMkS7dixI2ouLi4u6mvbtvsd66vvzNXmr/U4GzduVCQScW4tLS3Xe1oAAGAIinno3H777Ro/fnzUsXHjxunMmTOSJJ/PJ0n9dl1aW1udXR6fz6euri6Fw+Frzly4cKHf81+8eLHfbtGnPB6P0tLSom4AAMBcMQ+dadOm6eTJk1HHTp06pTvvvFOSlJ2dLZ/Pp5qaGuf+rq4u1dbWaurUqZKkvLw8JSYmRs2cP39ex44dc2YKCgoUiUTU0NDgzBw6dEiRSMSZAQAAw1tCrB/w8ccf19SpU1VaWqoFCxaooaFBlZWVqqyslHTl103BYFClpaXKyclRTk6OSktLlZKSopKSEkmSZVlavHix1q5dq4yMDKWnp2vdunWaOHGiZs+eLenKLtG8efO0ZMkS7dy5U5K0dOlSFRUVXdc7rgAAgPliHjr33nuvqqqqtHHjRj3zzDPKzs7WCy+8oIULFzozTz75pDo6OrR8+XKFw2Hl5+dr3759Sk1NdWa2bdumhIQELViwQB0dHZo1a5Z27dql+Ph4Z+b111/X6tWrnXdnFRcXq6KiItanBAAAhqiYf47OUMLn6JiNz9FxH5+jA2AguPo5OgAAAIMFoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWIQOAAAwFqEDAACMRegAAABjEToAAMBYhA4AADAWoQMAAIw14KFTVlamuLg4BYNB55ht29q0aZP8fr+Sk5M1c+ZMHT9+POr7Ojs7tWrVKo0ePVojR45UcXGxzp49GzUTDocVCARkWZYsy1IgENClS5cG+pQAAMAQMaChc/jwYVVWVupzn/tc1PHy8nJt3bpVFRUVOnz4sHw+n+bMmaP29nZnJhgMqqqqSnv27FFdXZ0uX76soqIi9fT0ODMlJSVqampSdXW1qqur1dTUpEAgMJCnBAAAhpABC53Lly9r4cKFevnllzVq1CjnuG3beuGFF/Stb31LX/nKV5Sbm6tXXnlFH330kXbv3i1JikQi+uEPf6jnn39es2fP1qRJk/Taa6/p6NGj+u///m9J0okTJ1RdXa3//M//VEFBgQoKCvTyyy/r5z//uU6ePHnVNXV2dqqtrS3qBgAAzDVgobNixQrNnz9fs2fPjjre3NysUCikwsJC55jH49GMGTN04MABSVJjY6O6u7ujZvx+v3Jzc52ZgwcPyrIs5efnOzNTpkyRZVnOTF9lZWXOr7ksy1JWVlbMzhcAAAw+AxI6e/bs0ZEjR1RWVtbvvlAoJEnyer1Rx71er3NfKBRSUlJS1E7Q1WYyMzP7PX5mZqYz09fGjRsViUScW0tLy42fHAAAGDISYv2ALS0teuyxx7Rv3z7dcsstf3MuLi4u6mvbtvsd66vvzNXmr/U4Ho9HHo/nms8BAADMEfMdncbGRrW2tiovL08JCQlKSEhQbW2tvv/97yshIcHZyem769La2urc5/P51NXVpXA4fM2ZCxcu9Hv+ixcv9tstAgAAw1PMQ2fWrFk6evSompqanNvkyZO1cOFCNTU16e6775bP51NNTY3zPV1dXaqtrdXUqVMlSXl5eUpMTIyaOX/+vI4dO+bMFBQUKBKJqKGhwZk5dOiQIpGIMwMAAIa3mP/qKjU1Vbm5uVHHRo4cqYyMDOd4MBhUaWmpcnJylJOTo9LSUqWkpKikpESSZFmWFi9erLVr1yojI0Pp6elat26dJk6c6Ly4edy4cZo3b56WLFminTt3SpKWLl2qoqIijR07NtanBQAAhqCYh871ePLJJ9XR0aHly5crHA4rPz9f+/btU2pqqjOzbds2JSQkaMGCBero6NCsWbO0a9cuxcfHOzOvv/66Vq9e7bw7q7i4WBUVFTf9fAAAwOAUZ9u27fYi3NLW1ibLshSJRJSWlub2chBjd214y+0lDHvvb57v9hIAGOhGfn7zt64AAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxEtxeAABz3bXhLVef//3N8119fgDuY0cHAAAYi9ABAADGInQAAICxCB0AAGAsXoyMAeP2C1EBAGBHBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxYh46ZWVluvfee5WamqrMzEw98MADOnnyZNSMbdvatGmT/H6/kpOTNXPmTB0/fjxqprOzU6tWrdLo0aM1cuRIFRcX6+zZs1Ez4XBYgUBAlmXJsiwFAgFdunQp1qcEAACGqJiHTm1trVasWKH6+nrV1NTok08+UWFhoT788ENnpry8XFu3blVFRYUOHz4sn8+nOXPmqL293ZkJBoOqqqrSnj17VFdXp8uXL6uoqEg9PT3OTElJiZqamlRdXa3q6mo1NTUpEAjE+pQAAMAQFWfbtj2QT3Dx4kVlZmaqtrZW9913n2zblt/vVzAY1Pr16yVd2b3xer3asmWLli1bpkgkottuu02vvvqqHnzwQUnSuXPnlJWVpbfffltz587ViRMnNH78eNXX1ys/P1+SVF9fr4KCAr333nsaO3Zsv7V0dnaqs7PT+bqtrU1ZWVmKRCJKS0sbyMswLN214S23l4Bh7v3N891eAoAB0NbWJsuyruvn94C/RicSiUiS0tPTJUnNzc0KhUIqLCx0Zjwej2bMmKEDBw5IkhobG9Xd3R014/f7lZub68wcPHhQlmU5kSNJU6ZMkWVZzkxfZWVlzq+5LMtSVlZWbE8WAAAMKgMaOrZta82aNZo+fbpyc3MlSaFQSJLk9XqjZr1er3NfKBRSUlKSRo0adc2ZzMzMfs+ZmZnpzPS1ceNGRSIR59bS0vKPnSAAABjUEgbywVeuXKnf//73qqur63dfXFxc1Ne2bfc71lffmavNX+txPB6PPB7P9SwdAAAYYMB2dFatWqW9e/dq//79uuOOO5zjPp9PkvrturS2tjq7PD6fT11dXQqHw9ecuXDhQr/nvXjxYr/dIgAAMDzFPHRs29bKlSv1k5/8RL/+9a+VnZ0ddX92drZ8Pp9qamqcY11dXaqtrdXUqVMlSXl5eUpMTIyaOX/+vI4dO+bMFBQUKBKJqKGhwZk5dOiQIpGIMwMAAIa3mP/qasWKFdq9e7d+9rOfKTU11dm5sSxLycnJiouLUzAYVGlpqXJycpSTk6PS0lKlpKSopKTEmV28eLHWrl2rjIwMpaena926dZo4caJmz54tSRo3bpzmzZunJUuWaOfOnZKkpUuXqqio6KrvuAIAAMNPzENnx44dkqSZM2dGHf/Rj36kf/3Xf5UkPfnkk+ro6NDy5csVDoeVn5+vffv2KTU11Znftm2bEhIStGDBAnV0dGjWrFnatWuX4uPjnZnXX39dq1evdt6dVVxcrIqKilifEgAAGKIG/HN0BrMbeR8+bhyfowO38Tk6gJkG1efoAAAAuIXQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGCvB7QUAwEC5a8Nbrj7/+5vnu/r8ANjRAQAABiN0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADGInQAAICxEtxeAAbOXRvecnsJAAC4ih0dAABgLEIHAAAYi9ABAADGInQAAICxCB0AAGAsQgcAABiLt5cDwAAZDB/x8P7m+W4vAXAVOzoAAMBYhA4AADAWoQMAAIxF6AAAAGMROgAAwFiEDgAAMBahAwAAjEXoAAAAYxE6AADAWHwyMgAYzO1PZ+aTmeG2Ib+j8+KLLyo7O1u33HKL8vLy9M4777i9JAAAMEgM6R2dN954Q8FgUC+++KKmTZumnTt36ktf+pLeffddjRkzxu3luf5/UgAADHdxtm3bbi/i75Wfn68vfvGL2rFjh3Ns3LhxeuCBB1RWVtZvvrOzU52dnc7XkUhEY8aMUUtLi9LS0mK+vtynfhnzxwQADB3Hnp7r9hKM1NbWpqysLF26dEmWZV1zdsju6HR1damxsVEbNmyIOl5YWKgDBw5c9XvKysr09NNP9zuelZU1IGsEAAxv1gtur8Bs7e3t5obOn//8Z/X09Mjr9UYd93q9CoVCV/2ejRs3as2aNc7Xvb29+utf/6qMjAzFxcXFdH2f1uZA7RYNRVyT/rgmV8d16Y9r0h/X5OqGw3WxbVvt7e3y+/2fOTtkQ+dTfQPFtu2/GS0ej0cejyfq2K233jpQS5MkpaWlGfsP7e/FNemPa3J1XJf+uCb9cU2uzvTr8lk7OZ8asu+6Gj16tOLj4/vt3rS2tvbb5QEAAMPTkA2dpKQk5eXlqaamJup4TU2Npk6d6tKqAADAYDKkf3W1Zs0aBQIBTZ48WQUFBaqsrNSZM2f0zW9+0+2lyePx6Kmnnur3q7LhjGvSH9fk6rgu/XFN+uOaXB3XJdqQfnu5dOUDA8vLy3X+/Hnl5uZq27Ztuu+++9xeFgAAGASGfOgAAAD8LUP2NToAAACfhdABAADGInQAAICxCB0AAGAsQieGysrKdO+99yo1NVWZmZl64IEHdPLkSbeXNaiUlZUpLi5OwWDQ7aW47oMPPtDDDz+sjIwMpaSk6Atf+IIaGxvdXpZrPvnkE337299Wdna2kpOTdffdd+uZZ55Rb2+v20u7qX7zm9/o/vvvl9/vV1xcnH76059G3W/btjZt2iS/36/k5GTNnDlTx48fd2exN8m1rkl3d7fWr1+viRMnauTIkfL7/frGN76hc+fOubfgm+Sz/q38X8uWLVNcXJxeeOGFm7a+wYLQiaHa2lqtWLFC9fX1qqmp0SeffKLCwkJ9+OGHbi9tUDh8+LAqKyv1uc99zu2luC4cDmvatGlKTEzUL37xC7377rt6/vnnB/xPkgxmW7Zs0UsvvaSKigqdOHFC5eXleu6557R9+3a3l3ZTffjhh/r85z+vioqKq95fXl6urVu3qqKiQocPH5bP59OcOXPU3t5+k1d681zrmnz00Uc6cuSIvvOd7+jIkSP6yU9+olOnTqm4uNiFld5cn/Vv5VM//elPdejQoev6u1BGsjFgWltbbUl2bW2t20txXXt7u52Tk2PX1NTYM2bMsB977DG3l+Sq9evX29OnT3d7GYPK/Pnz7UcffTTq2Fe+8hX74YcfdmlF7pNkV1VVOV/39vbaPp/P3rx5s3Ps448/ti3Lsl966SUXVnjz9b0mV9PQ0GBLsk+fPn1zFjUI/K3rcvbsWfuf/umf7GPHjtl33nmnvW3btpu+NrexozOAIpGIJCk9Pd3llbhvxYoVmj9/vmbPnu32UgaFvXv3avLkyfra176mzMxMTZo0SS+//LLby3LV9OnT9atf/UqnTp2SJP3ud79TXV2dvvzlL7u8ssGjublZoVBIhYWFzjGPx6MZM2bowIEDLq5scIlEIoqLixvWO6SS1Nvbq0AgoCeeeEITJkxwezmuGdJ/AmIws21ba9as0fTp05Wbm+v2cly1Z88eHTlyRIcPH3Z7KYPGn/70J+3YsUNr1qzRv/3bv6mhoUGrV6+Wx+PRN77xDbeX54r169crEononnvuUXx8vHp6evTss8/q61//uttLGzQ+/SPGff9wsdfr1enTp91Y0qDz8ccfa8OGDSopKTH6L3dfjy1btighIUGrV692eymuInQGyMqVK/X73/9edXV1bi/FVS0tLXrssce0b98+3XLLLW4vZ9Do7e3V5MmTVVpaKkmaNGmSjh8/rh07dgzb0HnjjTf02muvaffu3ZowYYKampoUDAbl9/u1aNEit5c3qMTFxUV9bdt2v2PDUXd3tx566CH19vbqxRdfdHs5rmpsbNT3vvc9HTlyZNj/2+BXVwNg1apV2rt3r/bv36877rjD7eW4qrGxUa2trcrLy1NCQoISEhJUW1ur73//+0pISFBPT4/bS3TF7bffrvHjx0cdGzdunM6cOePSitz3xBNPaMOGDXrooYc0ceJEBQIBPf744yorK3N7aYOGz+eT9P93dj7V2trab5dnuOnu7taCBQvU3NysmpqaYb+b884776i1tVVjxoxx/tt7+vRprV27VnfddZfby7up2NGJIdu2tWrVKlVVVel//ud/lJ2d7faSXDdr1iwdPXo06tgjjzyie+65R+vXr1d8fLxLK3PXtGnT+n30wKlTp3TnnXe6tCL3ffTRRxoxIvr/veLj44fd28uvJTs7Wz6fTzU1NZo0aZIkqaurS7W1tdqyZYvLq3PPp5Hzhz/8Qfv371dGRobbS3JdIBDo95rIuXPnKhAI6JFHHnFpVe4gdGJoxYoV2r17t372s58pNTXV+b8uy7KUnJzs8urckZqa2u81SiNHjlRGRsawfu3S448/rqlTp6q0tFQLFixQQ0ODKisrVVlZ6fbSXHP//ffr2Wef1ZgxYzRhwgT99re/1datW/Xoo4+6vbSb6vLly/rjH//ofN3c3Kympialp6drzJgxCgaDKi0tVU5OjnJyclRaWqqUlBSVlJS4uOqBda1r4vf79S//8i86cuSIfv7zn6unp8f5b296erqSkpLcWvaA+6x/K32DLzExUT6fT2PHjr3ZS3WXy+/6Moqkq95+9KMfub20QYW3l1/x5ptv2rm5ubbH47Hvueceu7Ky0u0luaqtrc1+7LHH7DFjxti33HKLfffdd9vf+ta37M7OTreXdlPt37//qv8dWbRokW3bV95i/tRTT9k+n8/2eDz2fffdZx89etTdRQ+wa12T5ubmv/nf3v3797u99AH1Wf9W+hquby+Ps23bvklNBQAAcFPxYmQAAGAsQgcAABiL0AEAAMYidAAAgLEIHQAAYCxCBwAAGIvQAQAAxiJ0AACAsQgdAABgLEIHAAAYi9ABAADG+n8BcXpirIsJYAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = open('names.txt', 'r').readlines()\n",
    "\n",
    "s = np.array([len(n) for n in d])-1\n",
    "plt.hist(s, bins=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jaskirat\\n',\n",
      " 'kalliope\\n',\n",
      " 'ovadia\\n',\n",
      " 'leonor\\n',\n",
      " 'javiah\\n',\n",
      " 'audrianna\\n',\n",
      " 'hazyl\\n',\n",
      " 'jayvon\\n',\n",
      " 'tylasia\\n',\n",
      " 'caily\\n']\n"
     ]
    }
   ],
   "source": [
    "samples = [random.choice(d) for _ in range(10)]\n",
    "pp(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033 29494 2539\n"
     ]
    }
   ],
   "source": [
    "u = len(d)\n",
    "v = len(list(set(d)))\n",
    "f = u - v\n",
    "print(u, v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0 1.0\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(n) for n in d]\n",
    "n = len(lengths)\n",
    "mu = sum(lengths) / n\n",
    "f = ((np.array(lengths)-mu)**2).sum()\n",
    "s = np.sqrt(f/n)\n",
    "print(round(mu, 0), round(s, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of long words = 1,693\n",
      "christoph\n",
      "sabastian\n",
      "jamielynn\n",
      "magdaleno\n",
      "keerthana\n",
      "angellina\n",
      "milagrace\n",
      "jullianna\n",
      "johnlucas\n",
      "chantelle\n"
     ]
    }
   ],
   "source": [
    "trash = [n for n in d if len(n) > 9]\n",
    "print(f'Number of long words = {len(trash):,}')\n",
    "samples = [random.choice(trash).strip() for _ in range(10)]\n",
    "for m in samples:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 ['\\n', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "v = sorted(list(set(''.join(d))))\n",
    "print(len(v), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20,859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT_conf(n_c=16, n_e=32, n_h=4, n_l=4, n_v=27, d=0.1, batch_size=8)\n",
      "53,147\n",
      "GPTModel(\n",
      "  (E): Embedding(27, 32)\n",
      "  (P): Embedding(16, 32)\n",
      "  (layers): Sequential(\n",
      "    (0): Block(\n",
      "      (norm_z): LayerNorm()\n",
      "      (mha): MHA(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (q): Linear(in_features=32, out_features=8, bias=True)\n",
      "            (k): Linear(in_features=32, out_features=8, bias=True)\n",
      "            (v): Linear(in_features=32, out_features=8, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (W_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (norm_a): LayerNorm()\n",
      "      (mlp): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (4): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm_z): LayerNorm()\n",
      "      (mha): MHA(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (q): Linear(in_features=32, out_features=8, bias=True)\n",
      "            (k): Linear(in_features=32, out_features=8, bias=True)\n",
      "            (v): Linear(in_features=32, out_features=8, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (W_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (norm_a): LayerNorm()\n",
      "      (mlp): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (4): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm_z): LayerNorm()\n",
      "      (mha): MHA(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (q): Linear(in_features=32, out_features=8, bias=True)\n",
      "            (k): Linear(in_features=32, out_features=8, bias=True)\n",
      "            (v): Linear(in_features=32, out_features=8, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (W_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (norm_a): LayerNorm()\n",
      "      (mlp): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (4): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm_z): LayerNorm()\n",
      "      (mha): MHA(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (q): Linear(in_features=32, out_features=8, bias=True)\n",
      "            (k): Linear(in_features=32, out_features=8, bias=True)\n",
      "            (v): Linear(in_features=32, out_features=8, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (W_o): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (norm_a): LayerNorm()\n",
      "      (mlp): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=32, bias=True)\n",
      "          (4): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (normalize_o): LayerNorm()\n",
      "  (mlp): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=32, out_features=27, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import GPTModel, GPT_conf\n",
    "from pprint import pprint as pp\n",
    "\n",
    "conf = GPT_conf()\n",
    "print(conf)\n",
    "model = GPTModel(conf)\n",
    "print(f'{model.number_of_parameters():,}')\n",
    "pp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare, load_batch, run, encode\n",
    "import random"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
